{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5fcbe8-2f76-4940-a033-060a35f92089",
   "metadata": {},
   "source": [
    "# Sample training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95bf3bb0-e1f2-4f45-ad79-611c113bf623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Corpus:\n",
      "This is the first document.\n",
      "This document is the second document.\n",
      "And this is the third one.\n",
      "Is this the first document?\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "\n",
    "print(\"Training Corpus:\")\n",
    "for doc in corpus:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3a843e-8ca1-4511-98a6-ebff846c77c4",
   "metadata": {},
   "source": [
    "# Initialize vocabulary with unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9a23c1-e8a0-4e1d-b243-ef512e44f05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Vocabulary:\n",
      "[' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>']\n",
      "Vocabulary Size: 20\n",
      "\n",
      "Pre-tokenized Word Frequencies:\n",
      "{('T', 'h', 'i', 's', '</w>'): 2, ('i', 's', '</w>'): 3, ('t', 'h', 'e', '</w>'): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('t', 'h', 'i', 's', '</w>'): 2, ('t', 'h', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's', '</w>'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '</w>'): 1}\n"
     ]
    }
   ],
   "source": [
    "unique_chars = set()\n",
    "for doc in corpus:\n",
    "    for char in doc:\n",
    "        unique_chars.add(char)\n",
    "\n",
    "vocab = list(unique_chars)\n",
    "vocab.sort() # For consistent order of characters, making the vocabulary list predictable\n",
    "\n",
    "# Add a special end-of-word token\n",
    "end_of_word = \"</w>\"\n",
    "vocab.append(end_of_word)\n",
    "\n",
    "print(\"Initial Vocabulary:\")\n",
    "print(vocab)\n",
    "print(f\"Vocabulary Size: {len(vocab)}\")\n",
    "\n",
    "# Pre-tokenize the corpus: Split into words and then characters\n",
    "# We'll split by space for simplicity and add the end-of-word token\n",
    "word_splits = {}\n",
    "for doc in corpus:\n",
    "    words = doc.split(' ')\n",
    "    for word in words:\n",
    "        char_list = list(word) + [end_of_word]\n",
    "        # Use tuple for immutability if storing counts later - you can't change tuple once it's created (values, order, adding, removing elements, etc.), so they can be used as dictionary keys because of that.\n",
    "        word_tuple = tuple(char_list)\n",
    "        if word_tuple not in word_splits:\n",
    "             word_splits[word_tuple] = 0\n",
    "        word_splits[word_tuple] += 1 # Count frequency of each initial word split\n",
    "\n",
    "print(\"\\nPre-tokenized Word Frequencies:\")\n",
    "print(word_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a9a2924-ad93-478b-97f2-474168445643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def get_pair_stats(splits):\n",
    "    \"\"\"Counts the frequency of adjacent pairs in the word splits.\"\"\"\n",
    "    # Initialize a dictionary with default values of 0 to count pairs of symbols.\n",
    "    # defaultdict: It's like a regular dictionary (dict), but with a key difference.\n",
    "    # If you try to access or modify a key that doesn't exist, instead of raising a KeyError,\n",
    "    # it automatically creates that key and assigns it a default value.\n",
    "    # int: This is the \"default factory\" you provide when creating the defaultdict. When a new key is created, it needs a default value, defaultdict calls this factory function. int() called with no arguments returns 0.\n",
    "    pair_counts = collections.defaultdict(int)\n",
    "    for word_tuple, freq in splits.items():\n",
    "        symbols = list(word_tuple)\n",
    "        for i in range(len(symbols) - 1):\n",
    "            pair = (symbols[i], symbols[i+1])\n",
    "            pair_counts[pair] += freq # Add the frequency of the word to the pair count\n",
    "    return pair_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb02300-51a8-4292-bb65-bc31c6356de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pair(pair_to_merge, splits):\n",
    "    \"\"\"Merges the specified pair in the word splits.\"\"\"\n",
    "    new_splits = {}\n",
    "    (first, second) = pair_to_merge\n",
    "    merged_token = first + second\n",
    "    for word_tuple, freq in splits.items():\n",
    "        symbols = list(word_tuple)\n",
    "        new_symbols = []\n",
    "        i = 0\n",
    "        while i < len(symbols):\n",
    "            # If the current and next symbol match the pair to merge\n",
    "            if i < len(symbols) - 1 and symbols[i] == first and symbols[i+1] == second:\n",
    "                new_symbols.append(merged_token)\n",
    "                i += 2 # Skip the next symbol\n",
    "            else:\n",
    "                new_symbols.append(symbols[i])\n",
    "                i += 1\n",
    "        new_splits[tuple(new_symbols)] = freq # Use the updated symbol list as the key\n",
    "    return new_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f3719-535d-4b2d-94cc-92ade2852965",
   "metadata": {},
   "source": [
    "# Iterative BPE Merging Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "febbba7e-036f-4d9b-b141-fd44ec511255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting BPE Merges ---\n",
      "Initial Splits: {('T', 'h', 'i', 's', '</w>'): 2, ('i', 's', '</w>'): 3, ('t', 'h', 'e', '</w>'): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('t', 'h', 'i', 's', '</w>'): 2, ('t', 'h', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's', '</w>'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '</w>'): 1}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 1/15\n",
      "Top 5 Pair Frequencies: [(('s', '</w>'), 8), (('i', 's'), 7), (('t', 'h'), 7), (('h', 'i'), 5), (('h', 'e'), 4)]\n",
      "Found Best Pair: ('s', '</w>') with Frequency: 8\n",
      "Merging ('s', '</w>') into 's</w>'\n",
      "Splits after merge: {('T', 'h', 'i', 's</w>'): 2, ('i', 's</w>'): 3, ('t', 'h', 'e', '</w>'): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('t', 'h', 'i', 's</w>'): 2, ('t', 'h', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>']\n",
      "Updated Merges: {('s', '</w>'): 's</w>'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 2/15\n",
      "Top 5 Pair Frequencies: [(('i', 's</w>'), 7), (('t', 'h'), 7), (('h', 'i'), 5), (('h', 'e'), 4), (('e', '</w>'), 4)]\n",
      "Found Best Pair: ('i', 's</w>') with Frequency: 7\n",
      "Merging ('i', 's</w>') into 'is</w>'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('t', 'h', 'e', '</w>'): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('t', 'h', 'is</w>'): 2, ('t', 'h', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 3/15\n",
      "Top 5 Pair Frequencies: [(('t', 'h'), 7), (('h', 'is</w>'), 4), (('h', 'e'), 4), (('e', '</w>'), 4), (('d', 'o'), 4)]\n",
      "Found Best Pair: ('t', 'h') with Frequency: 7\n",
      "Merging ('t', 'h') into 'th'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('th', 'e', '</w>'): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 4/15\n",
      "Top 5 Pair Frequencies: [(('th', 'e'), 4), (('e', '</w>'), 4), (('d', 'o'), 4), (('o', 'c'), 4), (('c', 'u'), 4)]\n",
      "Found Best Pair: ('th', 'e') with Frequency: 4\n",
      "Merging ('th', 'e') into 'the'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the', '</w>'): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 5/15\n",
      "Top 5 Pair Frequencies: [(('the', '</w>'), 4), (('d', 'o'), 4), (('o', 'c'), 4), (('c', 'u'), 4), (('u', 'm'), 4)]\n",
      "Found Best Pair: ('the', '</w>') with Frequency: 4\n",
      "Merging ('the', '</w>') into 'the</w>'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.', '</w>'): 2, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('d', 'o', 'c', 'u', 'm', 'e', 'n', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 6/15\n",
      "Top 5 Pair Frequencies: [(('d', 'o'), 4), (('o', 'c'), 4), (('c', 'u'), 4), (('u', 'm'), 4), (('m', 'e'), 4)]\n",
      "Found Best Pair: ('d', 'o') with Frequency: 4\n",
      "Merging ('d', 'o') into 'do'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('do', 'c', 'u', 'm', 'e', 'n', 't', '.', '</w>'): 2, ('do', 'c', 'u', 'm', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('do', 'c', 'u', 'm', 'e', 'n', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>', 'do']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>', ('d', 'o'): 'do'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 7/15\n",
      "Top 5 Pair Frequencies: [(('do', 'c'), 4), (('c', 'u'), 4), (('u', 'm'), 4), (('m', 'e'), 4), (('e', 'n'), 4)]\n",
      "Found Best Pair: ('do', 'c') with Frequency: 4\n",
      "Merging ('do', 'c') into 'doc'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('doc', 'u', 'm', 'e', 'n', 't', '.', '</w>'): 2, ('doc', 'u', 'm', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('doc', 'u', 'm', 'e', 'n', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>', 'do', 'doc']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>', ('d', 'o'): 'do', ('do', 'c'): 'doc'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 8/15\n",
      "Top 5 Pair Frequencies: [(('doc', 'u'), 4), (('u', 'm'), 4), (('m', 'e'), 4), (('e', 'n'), 4), (('n', 't'), 4)]\n",
      "Found Best Pair: ('doc', 'u') with Frequency: 4\n",
      "Merging ('doc', 'u') into 'docu'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('docu', 'm', 'e', 'n', 't', '.', '</w>'): 2, ('docu', 'm', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('docu', 'm', 'e', 'n', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>', 'do', 'doc', 'docu']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 9/15\n",
      "Top 5 Pair Frequencies: [(('docu', 'm'), 4), (('m', 'e'), 4), (('e', 'n'), 4), (('n', 't'), 4), (('i', 'r'), 3)]\n",
      "Found Best Pair: ('docu', 'm') with Frequency: 4\n",
      "Merging ('docu', 'm') into 'docum'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('docum', 'e', 'n', 't', '.', '</w>'): 2, ('docum', 'e', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('docum', 'e', 'n', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>', 'do', 'doc', 'docu', 'docum']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 10/15\n",
      "Top 5 Pair Frequencies: [(('docum', 'e'), 4), (('e', 'n'), 4), (('n', 't'), 4), (('i', 'r'), 3), (('t', '</w>'), 3)]\n",
      "Found Best Pair: ('docum', 'e') with Frequency: 4\n",
      "Merging ('docum', 'e') into 'docume'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('docume', 'n', 't', '.', '</w>'): 2, ('docume', 'n', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('docume', 'n', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>', 'do', 'doc', 'docu', 'docum', 'docume']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 11/15\n",
      "Top 5 Pair Frequencies: [(('docume', 'n'), 4), (('n', 't'), 4), (('i', 'r'), 3), (('t', '</w>'), 3), (('.', '</w>'), 3)]\n",
      "Found Best Pair: ('docume', 'n') with Frequency: 4\n",
      "Merging ('docume', 'n') into 'documen'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('documen', 't', '.', '</w>'): 2, ('documen', 't', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('documen', 't', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>', 'do', 'doc', 'docu', 'docum', 'docume', 'documen']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume', ('docume', 'n'): 'documen'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 12/15\n",
      "Top 5 Pair Frequencies: [(('documen', 't'), 4), (('i', 'r'), 3), (('t', '</w>'), 3), (('.', '</w>'), 3), (('d', '</w>'), 3)]\n",
      "Found Best Pair: ('documen', 't') with Frequency: 4\n",
      "Merging ('documen', 't') into 'document'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'i', 'r', 's', 't', '</w>'): 2, ('document', '.', '</w>'): 2, ('document', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'i', 'r', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('document', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>', 'do', 'doc', 'docu', 'docum', 'docume', 'documen', 'document']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume', ('docume', 'n'): 'documen', ('documen', 't'): 'document'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 13/15\n",
      "Top 5 Pair Frequencies: [(('i', 'r'), 3), (('.', '</w>'), 3), (('d', '</w>'), 3), (('T', 'h'), 2), (('h', 'is</w>'), 2)]\n",
      "Found Best Pair: ('i', 'r') with Frequency: 3\n",
      "Merging ('i', 'r') into 'ir'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'ir', 's', 't', '</w>'): 2, ('document', '.', '</w>'): 2, ('document', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'ir', 'd', '</w>'): 1, ('o', 'n', 'e', '.', '</w>'): 1, ('I', 's</w>'): 1, ('document', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>', 'do', 'doc', 'docu', 'docum', 'docume', 'documen', 'document', 'ir']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume', ('docume', 'n'): 'documen', ('documen', 't'): 'document', ('i', 'r'): 'ir'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 14/15\n",
      "Top 5 Pair Frequencies: [(('.', '</w>'), 3), (('d', '</w>'), 3), (('T', 'h'), 2), (('h', 'is</w>'), 2), (('f', 'ir'), 2)]\n",
      "Found Best Pair: ('.', '</w>') with Frequency: 3\n",
      "Merging ('.', '</w>') into '.</w>'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'ir', 's', 't', '</w>'): 2, ('document', '.</w>'): 2, ('document', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd', '</w>'): 1, ('A', 'n', 'd', '</w>'): 1, ('th', 'is</w>'): 2, ('th', 'ir', 'd', '</w>'): 1, ('o', 'n', 'e', '.</w>'): 1, ('I', 's</w>'): 1, ('document', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>', 'do', 'doc', 'docu', 'docum', 'docume', 'documen', 'document', 'ir', '.</w>']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume', ('docume', 'n'): 'documen', ('documen', 't'): 'document', ('i', 'r'): 'ir', ('.', '</w>'): '.</w>'}\n",
      "------------------------------\n",
      "\n",
      "Merge Iteration 15/15\n",
      "Top 5 Pair Frequencies: [(('d', '</w>'), 3), (('T', 'h'), 2), (('h', 'is</w>'), 2), (('f', 'ir'), 2), (('ir', 's'), 2)]\n",
      "Found Best Pair: ('d', '</w>') with Frequency: 3\n",
      "Merging ('d', '</w>') into 'd</w>'\n",
      "Splits after merge: {('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'ir', 's', 't', '</w>'): 2, ('document', '.</w>'): 2, ('document', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd</w>'): 1, ('A', 'n', 'd</w>'): 1, ('th', 'is</w>'): 2, ('th', 'ir', 'd</w>'): 1, ('o', 'n', 'e', '.</w>'): 1, ('I', 's</w>'): 1, ('document', '?', '</w>'): 1}\n",
      "Updated Vocabulary: [' ', '.', '?', 'A', 'I', 'T', 'c', 'd', 'e', 'f', 'h', 'i', 'm', 'n', 'o', 'r', 's', 't', 'u', '</w>', 's</w>', 'is</w>', 'th', 'the', 'the</w>', 'do', 'doc', 'docu', 'docum', 'docume', 'documen', 'document', 'ir', '.</w>', 'd</w>']\n",
      "Updated Merges: {('s', '</w>'): 's</w>', ('i', 's</w>'): 'is</w>', ('t', 'h'): 'th', ('th', 'e'): 'the', ('the', '</w>'): 'the</w>', ('d', 'o'): 'do', ('do', 'c'): 'doc', ('doc', 'u'): 'docu', ('docu', 'm'): 'docum', ('docum', 'e'): 'docume', ('docume', 'n'): 'documen', ('documen', 't'): 'document', ('i', 'r'): 'ir', ('.', '</w>'): '.</w>', ('d', '</w>'): 'd</w>'}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- BPE Training Loop Initialization ---\n",
    "num_merges = 15\n",
    "# Stores merge rules, e.g., {('a', 'b'): 'ab'}\n",
    "# Example: {('T', 'h'): 'Th'}\n",
    "merges = {}\n",
    "# Initial word splits: {('T', 'h', 'i', 's', '</w>'): 2, ('i', 's', '</w>'): 2, ...}\n",
    "current_splits = word_splits.copy() # Start with initial word splits\n",
    "\n",
    "print(\"\\n--- Starting BPE Merges ---\")\n",
    "print(f\"Initial Splits: {current_splits}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for i in range(num_merges):\n",
    "    print(f\"\\nMerge Iteration {i+1}/{num_merges}\")\n",
    "\n",
    "    # 1. Calculate Pair Frequencies\n",
    "    pair_stats = get_pair_stats(current_splits)\n",
    "    if not pair_stats:\n",
    "        print(\"No more pairs to merge.\")\n",
    "        break\n",
    "    # Optional: Print top 5 pairs for inspection\n",
    "    sorted_pairs = sorted(pair_stats.items(), key=lambda item: item[1], reverse=True)\n",
    "    print(f\"Top 5 Pair Frequencies: {sorted_pairs[:5]}\")\n",
    "\n",
    "    # 2. Find Best Pair\n",
    "    # The 'max' function iterates over all key-value pairs in the 'pair_stats' dictionary\n",
    "    # The 'key=pair_stats.get' tells 'max' to use the frequency (value) for comparison, not the pair (key) itself\n",
    "    # This way, 'max' selects the pair with the highest frequency\n",
    "    best_pair = max(pair_stats, key=pair_stats.get)\n",
    "    best_freq = pair_stats[best_pair]\n",
    "    print(f\"Found Best Pair: {best_pair} with Frequency: {best_freq}\")\n",
    "\n",
    "    # 3. Merge the Best Pair\n",
    "    current_splits = merge_pair(best_pair, current_splits)\n",
    "    new_token = best_pair[0] + best_pair[1]\n",
    "    print(f\"Merging {best_pair} into '{new_token}'\")\n",
    "    print(f\"Splits after merge: {current_splits}\")\n",
    "\n",
    "    # 4. Update Vocabulary\n",
    "    vocab.append(new_token)\n",
    "    print(f\"Updated Vocabulary: {vocab}\")\n",
    "\n",
    "    # 5. Store Merge Rule\n",
    "    merges[best_pair] = new_token\n",
    "    print(f\"Updated Merges: {merges}\")\n",
    "\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f46718-4646-413a-b987-c96900e0cbf4",
   "metadata": {},
   "source": [
    "# Review the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcaab1e5-9980-43a2-89e8-677e48241350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BPE Merges Complete ---\n",
      "Final Vocabulary Size: 35\n",
      "\n",
      "Learned Merges (Pair -> New Token):\n",
      "('s', '</w>') -> 's</w>'\n",
      "('i', 's</w>') -> 'is</w>'\n",
      "('t', 'h') -> 'th'\n",
      "('th', 'e') -> 'the'\n",
      "('the', '</w>') -> 'the</w>'\n",
      "('d', 'o') -> 'do'\n",
      "('do', 'c') -> 'doc'\n",
      "('doc', 'u') -> 'docu'\n",
      "('docu', 'm') -> 'docum'\n",
      "('docum', 'e') -> 'docume'\n",
      "('docume', 'n') -> 'documen'\n",
      "('documen', 't') -> 'document'\n",
      "('i', 'r') -> 'ir'\n",
      "('.', '</w>') -> '.</w>'\n",
      "('d', '</w>') -> 'd</w>'\n",
      "\n",
      "Final Word Splits after all merges:\n",
      "{('T', 'h', 'is</w>'): 2, ('is</w>',): 3, ('the</w>',): 4, ('f', 'ir', 's', 't', '</w>'): 2, ('document', '.</w>'): 2, ('document', '</w>'): 1, ('s', 'e', 'c', 'o', 'n', 'd</w>'): 1, ('A', 'n', 'd</w>'): 1, ('th', 'is</w>'): 2, ('th', 'ir', 'd</w>'): 1, ('o', 'n', 'e', '.</w>'): 1, ('I', 's</w>'): 1, ('document', '?', '</w>'): 1}\n",
      "\n",
      "Final Vocabulary (sorted):\n",
      "[' ', '.', '.</w>', '</w>', '?', 'A', 'I', 'T', 'c', 'd', 'd</w>', 'do', 'doc', 'docu', 'docum', 'docume', 'documen', 'document', 'e', 'f', 'h', 'i', 'ir', 'is</w>', 'm', 'n', 'o', 'r', 's', 's</w>', 't', 'th', 'the', 'the</w>', 'u']\n"
     ]
    }
   ],
   "source": [
    "# --- BPE Merges Complete ---\n",
    "print(\"\\n--- BPE Merges Complete ---\")\n",
    "print(f\"Final Vocabulary Size: {len(vocab)}\")\n",
    "print(\"\\nLearned Merges (Pair -> New Token):\")\n",
    "# Pretty print merges\n",
    "for pair, token in merges.items():\n",
    "    print(f\"{pair} -> '{token}'\")\n",
    "\n",
    "print(\"\\nFinal Word Splits after all merges:\")\n",
    "print(current_splits)\n",
    "\n",
    "print(\"\\nFinal Vocabulary (sorted):\")\n",
    "# Sort for consistent viewing\n",
    "final_vocab_sorted = sorted(list(set(vocab))) # Use set to remove potential duplicates if any step introduced them\n",
    "print(final_vocab_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd39e6-aad9-4d7c-ba5a-22fe3296533d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ollama)",
   "language": "python",
   "name": "ollama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
